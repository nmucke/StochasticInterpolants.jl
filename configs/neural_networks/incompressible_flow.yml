
training_args:
  batch_size: 8
  num_epochs: 1000
  max_learning_rate: 1.0e-4
  min_learning_rate: 1.0e-6
  num_warmup_steps: 10
  early_stop_patience: 10
  num_test_paths: 5
  num_test_sde_steps: 20
  test_frequency: 20

model_args:
  model_type: "conv_next_u_net"
  in_channels: 3
  out_channels: 3
  embedding_dims: 256
  channels: [16, 32, 64, 128]
  attention_type: "DiT" # "linear" or "standard" or "DiT"
  use_attention_in_layer: [false, false, false, false, true] # [true, true, true, true];
  attention_embedding_dims: 64
  num_heads: 4
  projection: nothing
  len_history: 2
  padding: "smooth"
  pars_dim: 1

optimizer_args:
  learning_rate: 1.0e-4
  weight_decay: 1.0e-8
  betas: [0.9, 0.999]

interpolant_args:
  alpha: "linear"
  beta: "quadratic"
  gamma: "linear"
  gamma_multiplier: 1.0e-1
  coefs: []

diffusion_args:
  type: "follmer_optimal"
  multiplier: 1.0e-1